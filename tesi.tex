\documentclass[12pt,a4paper]{report}
\usepackage[italian]{babel}
\usepackage{newlfont}
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{syntax}
\textwidth=450pt\oddsidemargin=0pt
\begin{document}

\input{cover}

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{1}
\tableofcontents

\hypertarget{introduzione}{%
\chapter{Introduzione}\label{introduzione}}

Da sempre, un elemento portante della società è lo scambio di risorse,
che ha condizionato ogni epoca. Normalmente concludere uno scambio
prevede la figura di un garante che impone delle regole affinché lo
scambio sia valido. Per la prima volta nella storia si hanno a
disposizione i mezzi per eliminare questa figura, perché si ha un
sistema in cui l'esistenza stessa di un contratto valida la transazione.
L'informatica attraverso la programmazione permette di realizzare questo
tipo di contratti, che nell'ambito vengono chiamati \emph{smart
contract}.

Gli \emph{smart contract} devono garantire le proprietà di fiducia,
affidabilità e di sicurezza, che in precedenza erano delegate al
garante, ma che adesso diventano possibili grazie alle blockchain.
Queste ultime sono code nelle quali è consentita l'operazione di
lettura, mentre l'unica operazione di scrittura è l'aggiunta (o
transazione): non è possibile quindi modificare un elemento già presente
nella blockchain; di conseguenza viene mantenuto un registro con la
storia di tutte le transazioni eseguite. Inoltre questa struttura dati è
distribuita, quindi è parte di una rete peer-to-peer in cui viene
replicata per ogni nodo. Di conseguenza le istanze di \emph{smart
contract}, se memorizzati nella blockchain, diventano programmi che
possono essere eseguiti in modo distribuito e sicuro, e che controllano
lo scambio di denaro tra diverse parti.

A livello di programmazione uno \emph{smart contract} è definito da un
identificativo univoco, da uno stato -- cioè i campi -- e da del codice,
inteso come insieme di metodi che modificano lo stato del contratto. Per
implementare \emph{smart contract} sono messi a disposizioni linguaggi
di programmazione dedicati, a ognuno dei quali è associata la relativa
blockchain, ad esempio troviamo il linguaggio Solidity per la blockchain
Ethereum o Liquidity per Tezos.

Siccome possono gestire considerevoli somme di denaro, il codice dei
contratti è codice critico: diventa quindi interessante fare analisi
statica sul comportamento degli \emph{smart contract}. In merito sono
stati fatti diversi lavori; di questi ne è particolarmente interessante
uno in cui emerge che, nel momento in cui un utente razionale agisce per
minimizzare le perdite di denaro (o equivalentemente per massimizzare il
guadagno), lo \emph{smart contract} lo può forzare a determinate
decisioni. Per esempio, chiedendo all'utente una cauzione che il
contratto restituirà solo in caso di suo comportamento fedele al
contratto, questi se vorrà massimizzare il guadagno si vedrà costretto a
rispettare il contratto. È anche possibile verificare algoritmicamente
il \emph{comportamento emergente} del sistema: ogni utente che è
egoisticamente interessato a massimizzare il suo guadagno non impedisce
agli altri utenti di fare lo stesso. Questa analisi è stata fatta
definendo un linguaggio, chiamato \texttt{scl} (Smart Calculus
Language), con un ristretto insieme di funzioni sugli \emph{smart
contract}, che permette di modellare il comportamento di contratti e
utenti (umani). \texttt{Scl} è un linguaggio ad attori object-based, che
rende più semplice l'analisi di \emph{smart contract} -- ma allo stesso
tempo espressivo abbastanza da essere Turing completo: permette
l'invocazione di metodi, la modifica dei campi, il comportamento
condizionale, la ricorsione, il sollevamento di eccezioni. Può essere
scritto un programma in \texttt{scl} che corrisponde a un modello dove
gli utenti e i contratti interagiscono tra loro. L'analisi associa
un'unica formula nell'aritmetica di Presburger che descrive lo spazio
delle possibili scelte, elaborandola si ottiene la strategia dell'utente
per massimizzare il profitto.

\texttt{Scl} precedentemente era un linguaggio solamente teorico, nel
senso che un programma in questo linguaggio non poteva essere eseguito
per la mancanza degli strumenti necessari. Il mio contributo è stato di
produrre questi strumenti per rendere effettivamente possibile l'uso di
\texttt{scl} in ulteriori analisi. Ho quindi definito un parser per dare
una sintassi a \texttt{scl}, e successivamente ho implementato un
compilatore verso un linguaggio per \emph{smart contract} già
conosciuto. L'obiettivo ultimo è stato quello di permettere la scrittura
e il deploy di \emph{smart contract} su una blockchain esistente usando
solo \texttt{scl}.

\hypertarget{presentazione-del-lavoro-svolto}{%
\section{Presentazione del lavoro
svolto}\label{presentazione-del-lavoro-svolto}}

In questa tesi mostriamo le tecniche usate, le caratteristiche
implementative e la risoluzione ai problemi riscontrati che hanno
portato alla realizzazione di questi tool di supporto al linguaggio
\texttt{scl}.

In particolare nel capitolo \ref{intrinsically-typed-data-structure}
introduciamo il problema del \emph{type checking}, che un compilatore
generico deve affrontare per controllare che i vincoli di tipo nel
programma da compilare siano rispettati. In merito, definiamo una
\emph{Intrinsically Type Data Structure} che permette la realizzazione
della strategia che abbiamo scelto di usare nel compilatore implementato
per fare \emph{type checking}. Questa tecnica prevede l'uso un albero di
sintassi astratta in cui la sua stessa struttura cattura sintatticamente
tutti e soli i programmi ben tipati, permettendo al compilatore di non
effettuare un controllo sui tipi dopo la costruzione dell'albero.
L'implementazione di una \emph{Intrinsically Typed Data Structure} è
possibile in pochi linguaggi funzionali: tra questi ci concentreremo su
OCaml -- che è anche il linguaggio che abbiamo usato per la
realizzazione di parser e compilatore -- vedendo che strumenti mette a
disposizione.

Nel capitolo \ref{smart-calculus-language} vediamo le caratteristiche
principali del linguaggio \texttt{scl}:, notiamo in particolare che il
linguaggio non presentava una sintassi che permettesse di scrivere in
maniera semplice i programmi, ma metteva già a disposizione un albero di
sintassi astratta che rendeva noti i costrutti del linguaggio. Viene
mostrata quindi la grammatica che abbiamo introdotto, grazie alla quale
il parser che abbiamo realizzato costruisce l'albero di derivazione.
Vediamo anche che l'albero di sintassi astratta era già definito da
\texttt{scl} come una struttura intrinsecamente tipata quindi a livello
di parsing non ci siamo dovuti preoccupare di un controllo di tipi
sull'albero avendo comunque la garanzia di rispettare i vincoli di tipo.

Una volta definite le strutture in input e in output del parser, nel
capitolo \ref{parsing} mostriamo l'aspetto implementativo. Ci siamo
preoccupati in primo luogo dell'analisi lessicale, in modo da poter
raggruppare i singoli caratteri in input in token. Poi abbiamo
implementato l'analizzatore sintattico che sui token in ingresso
costruisce l'albero di sintassi astratta. Il parser è stato implementato
grazie alla tecnica dei \emph{parser combinator}, strategia che consiste
nel definire funzioni che compongono dei parser (che a loro volta sono
funzioni) passati come in input alla funzione.

Dopo aver mostrato il parser, vediamo, nel capitolo \ref{compilazione}
il compilatore realizzato con lo scopo di rendere possibile
l'implementazione di un programma \texttt{scl} su una blockchain. Detto
compilatore da \texttt{scl} traduce nel linguaggio per \emph{smart
contract} Solidity del linguaggio \texttt{scl}. Essendo \texttt{scl} un
linguaggio molto più povero di costrutti rispetto a Solidity, la sua
compilazione non produce tutti i costrutti del linguaggio, ma solo verso
un sottoinsieme di quest'ultimo. In più mi preoccuperò solo di tradurre
gli attori contratti, poiché Solidity non dispone dei mezzi necessari
per la definizione degli utenti. Il compilatore in primo luogo traduce
l'albero di sintassi astratta di \texttt{scl} nell'analogo albero in
Solidity; successivamente da quest'ultimo genera l'effettivo codice
Solidity. L'albero di sintassi astratta di Solidity generato dalla
compilazione è intrinsecamente tipato, abbiamo quindi dovuto far
associare ad ogni programma ben tipato in \texttt{scl} lo stesso
programma ben tipato in Solidity. Questo è stato fatto creando una
corrispondenza di tipi di dato in \texttt{scl} e i tipi di Solidity --
una volta fatto questo è stato poi possibile tradurre tutti i costrutti
del linguaggio \texttt{scl} nei loro costrutti corrispondenti.

La compilazione in codice Solidity non si preoccupa però della creazione
sulla blockchain dei contratti. Nel capitolo \ref{deploy} mostriamo come
il compilatore generi anche uno script Python che, collegandosi alla
rete, si preoccupa della creazione dei contratti permettendo quindi di
fare il deploy sulla blockchain.

\newpage

\hypertarget{intrinsically-typed-data-structure}{%
\chapter{Intrinsically Typed Data
Structure}\label{intrinsically-typed-data-structure}}

\hypertarget{introduzione-1}{%
\section{Introduzione}\label{introduzione-1}}

Durante la compilazione verso un linguaggio qualsiasi, il compilatore si
deve preoccupare del \emph{type checking} cioè di quell'operazione che
verifica che i vincoli di tipo nel programma vengano rispettati. Ad
esempio un vincolo di tipo si ha in un assegnamento, dove è richiesto
che il tipo del \emph{left-hand side} (\emph{lhs}) sia compatibile con
il tipo del \emph{right-hand side} (\emph{rhs}), altrimenti si può
incorrere in diversi errori durante l'esecuzione.

Per garantire la coerenza di tipi nel parser e nel compilatore, invece
che usare le classiche tecniche, è stata scelta una tecnica emergente
presente in solo pochi linguaggi funzionali (tra cui OCaml), ovvero
l'uso di una \emph{Intrinsically Typed Data Structure}.

\hypertarget{approccio-al-type-checking}{%
\section{Approccio al type checking}\label{approccio-al-type-checking}}

Tradizionalmente il \emph{type checking} avviene nella fase di analisi
semantica nel processo di compilazione -- quindi dopo che è avvenuto il
parsing -- una volta che è stato costruito l'albero di sintassi astratta
(AST). Si ha così che il \emph{type checking} avviene esternamente
all'albero di derivazione: questo viene infatti sottoposto a un
controllo, dove per ogni sottoalbero viene valutato il tipo e nel nodo
viene verificato che i tipi dei relativi sottoalberi combacino.

In questo caso però, sia nel compilatore che nel parser, è stata usata
una tecnica differente per cui l'albero di sintassi astratta è un
\emph{Intrinsically Typed Data Structure}. Questo significa che l'albero
è una struttura dati con tipo dipendente -- è in relazione ai termini
all'interno della struttura -- che permette di esprimere tutti e i soli
programmi ben tipati. È quindi la struttura stessa che definisce che
cosa è ben tipato: non c'è bisogno quindi di implementare un \emph{type
checker} separato che analizzi l'albero, perché i vincoli di tipo sono
già all'interno della definizione stessa dell'albero. Il \emph{type
checking}, quindi, avviene direttamente nel momento della costruzione
dell'albero, facendo comunque rispettare i vincoli di tipo, ma in modo
più immediato e con un'implementazione più semplice.

Per implementare parser e compilatore, si è interessati quindi a
implementare un \emph{Intrinsically Typed Data Structure} in OCaml:
vediamo quindi gli strumenti che il linguaggio mette a disposizione.

\hypertarget{generic-algebraic-data-type}{%
\section{Generic Algebraic Data
Type}\label{generic-algebraic-data-type}}

In prima battuta occorre capire cosa sia un \emph{Algebraic Data Type}
(ADT) che OCaml permette di definire. Un ADT è un tipo composto definito
tramite intersezione o unione disgiunta di altri tipi. È mostrato un
esempio di ADT:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{type}\NormalTok{ expr =}
\NormalTok{ | Int }\KeywordTok{of} \DataTypeTok{int}
\NormalTok{ | Bool }\KeywordTok{of} \DataTypeTok{bool}
\NormalTok{ | And }\KeywordTok{of}\NormalTok{ expr * expr}
\NormalTok{ | Plus }\KeywordTok{of}\NormalTok{ expr * expr }
\NormalTok{ | Eq }\KeywordTok{of}\NormalTok{ expr * expr}
\end{Highlighting}
\end{Shaded}

In questo esempio un tipo \texttt{expr} può essere \texttt{Int} di un
intero, \texttt{Bool} di un booleano oppure \texttt{Plus}, \texttt{And}
o \texttt{Eq} di due altre \texttt{expr}. Si ha quindi un'unione
disgiunta di vari costruttori (che sono \texttt{Int}, \texttt{Bool},
\texttt{Plus}\ldots{}), e all'interno di alcuni si ha un'intersezione --
ad esempio all'interno di \texttt{Plus} dove si trova una coppia di
\texttt{expr}. Si nota però, che, sempre nell'esempio, se si costruisse
un'espressione \texttt{And((Int\ 9),(Bool\ true))} questa sarebbe
un'espressione sintatticamente corretta, ma non semanticamente: non
sarebbe ben tipata, siccome l'\texttt{And} si può fare solo tra tipi
booleani. È necessario, quindi che quando viene valuta l'espressione ci
sia un controllo di tipo: la funzione che si preoccupa della valutazione
sarebbe:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{rec}\NormalTok{ eval : expr -> int_or_bool =}
\KeywordTok{function}
\NormalTok{ | Int n -> I n}
\NormalTok{ | Bool b -> B b}
\NormalTok{ | And(e1,e2) ->}
\NormalTok{ (}\KeywordTok{match}\NormalTok{ eval e1, eval e2 }\KeywordTok{with}
\NormalTok{    B n, B m -> B (n && m)}
\NormalTok{    | _, _ -> }\DataTypeTok{raise}\NormalTok{ TypeError)}
\NormalTok{ | ... }
\end{Highlighting}
\end{Shaded}

In questo modo scrivendo \texttt{And((Int\ 9),(Bool\ true))} non si
riscontrerebbe nessun errore a tempo di compilazione, ma se si cercasse
di calcolare \texttt{eval\ (And((Int\ 9),(Bool\ true)))} allora sarebbe
sollevata un'eccezione a tempo di esecuzione.

Sempre con l'obiettivo di avere delle strutture \emph{Intrinsically
typed} si è interessati a un costrutto in cui la sintassi della
struttura stessa possa permettere di scrivere espressioni solo ben
tipate (il concetto stesso di ben tipato è in realtà definito dalla
stessa struttura). OCaml infatti mette a disposizione anche
\emph{Generalized Algebraic Data Type} (GADT), che come suggerisce il
nome è la generalizzazione degli ADT. Come d'altronde era già permesso
negli ADT, i GADT permettono di definire dei tipi parametrici -- ma in
più si ha la possibilità di vincolare sintatticamente il parametro al
momento della sua istanziazione con il tipo di ritorno dei costruttori
del GADT (che dovrà essere specificato).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{type}\NormalTok{ 'a expr =}
\NormalTok{| Int : }\DataTypeTok{int}\NormalTok{ -> }\DataTypeTok{int}\NormalTok{ expr}
\NormalTok{| Bool : }\DataTypeTok{bool}\NormalTok{ -> }\DataTypeTok{bool}\NormalTok{ expr}
\NormalTok{| And : }\DataTypeTok{bool}\NormalTok{ expr * }\DataTypeTok{bool}\NormalTok{ expr -> }\DataTypeTok{bool}\NormalTok{ expr}
\NormalTok{| Plus : }\DataTypeTok{int}\NormalTok{ expr * }\DataTypeTok{int}\NormalTok{ expr -> }\DataTypeTok{int}\NormalTok{ expr}
\NormalTok{| Eq : 'a expr * 'a expr -> }\DataTypeTok{bool}\NormalTok{ expr}
\end{Highlighting}
\end{Shaded}

In questo esempio, quindi, l'espressione
\texttt{And((Int\ 9),(Bool\ true))} risulterebbe mal tipata, in quanto
non conforme alla struttura appena definita, dal momento che il
costruttore \texttt{And} richiederebbe una coppia di espressioni
booleane, ma il primo elemento della coppia \texttt{Int\ 9} è definito
come un'espressione intera. Scrivendo infatti
\texttt{And((Int\ 9),(Bool\ true))} in codice OCaml, sarebbe sollevato
un errore a tempo di compilazione. Definendo così il tipo \texttt{expr}
anche la valutazione del tipo risulta più semplice rispetto all'analoga
nel caso del ADT, infatti non ci si deve preoccupare di nessun controllo
di tipo:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{rec}\NormalTok{ eval: : }\KeywordTok{type}\NormalTok{ a. a expr -> a =}
\KeywordTok{function}
\NormalTok{ | Int n -> n}
\NormalTok{ | Bool b -> b}
\NormalTok{ | And(e1,e2) -> (eval e1) && (eval e2)}
\NormalTok{ | ... }
\end{Highlighting}
\end{Shaded}

Si ha quindi che la struttura del tipo \texttt{expr} definita con l'uso
degli GADT vincola sintatticamente a scrivere espressioni ben tipate:
ciò significa che \texttt{expr} è intrinsecamente tipata. Quindi
l'implementazione dell'albero di sintassi astratta, sarà del tutto
analoga a quella di \texttt{expr}, dove i costruttori, invece di essere
relativi alle espressioni saranno relativi ai costrutti di un programma
nel linguaggio.

\hypertarget{conclusione}{%
\section{Conclusione}\label{conclusione}}

Si è quindi visto che i GADT permettono la definizione di
\emph{Intrinsically Typed Data Structure}: usando questa tecnica
nell'implementazione del parser e del compilatore in questione, si può
quindi evitare di dover essere ridondanti nell'eseguire il type
checking, avendo la certezza che il codice sia ben tipato e con meno
probabilità che si presentino bug.

\newpage

\hypertarget{smart-calculus-language}{%
\chapter{Smart Calculus Language}\label{smart-calculus-language}}

\hypertarget{introduzione-2}{%
\section{Introduzione}\label{introduzione-2}}

In questa sezione si inizia a descrivere il parser, senza analizzare,
per ora, l'aspetto implementativo. Viene in un primo luogo descritto
\texttt{scl}, il linguaggio verso il quale viene fatto il parsing, poi
viene definita la grammatica che dà luogo a una sintassi per
\texttt{scl}, e infine per tale grammatica si mostra il relativo albero
di sintassi astratta tipato generato dal parser, in maniera da definire
chiaramente la struttura dell'input e dell'output del parser.

\hypertarget{descrizione-del-linguaggio-scl}{%
\section{\texorpdfstring{Descrizione del linguaggio
\texttt{scl}}{Descrizione del linguaggio scl}}\label{descrizione-del-linguaggio-scl}}

\texttt{Scl} è un linguaggio imperativo ad attori (come per esempio
\texttt{Erlang}) che permette di descrivere il comportamento di
contratti e umani -- cioè gli utenti che interagiscono sui contratti.
\texttt{Scl} è un linguaggio usato per l'analisi di \emph{smart
contract}, quindi, con l'obiettivo di fare un'analisi più mirata,
semplice ed essenziale, è stato reso volutamente minimale. Nonostante
ciò \texttt{scl} è un linguaggio Turing completo, in quanto permette
l'assegnamento, l'istruzione condizionale, l'invocazione di funzioni, la
ricorsione e l'esecuzione di transazioni (con significato nel contesto
delle basi di dati).

Un programma \texttt{scl} consiste in una una configurazione, ovvero un
insieme di attori (contratti o umani) che vengono definiti con campi e
metodi, in maniera analoga ai linguaggi di programmazione a oggetti. Si
ha che ogni attore conosce tutti gli altri attori della configurazione,
rendendo possibile -- per esempio -- che un umano chiami un metodo di
uno specifico contratto, senza avere bisogno di parametri o campi
aggiuntivi.

Sebbene siano due entità distinte, il codice di contratti e degli umani
è molto simile. La differenza principale è che un contratto può
sollevare un'eccezione, mentre l'umano può osservare il fallimento dei
contratti catturando l'eccezione e prendendo decisioni di conseguenza.
Gli umani hanno anche a disposizione l'operazione di scelta, che
consiste in un operatore non deterministico con il quale non si sa a
priori quale codice l'umano andrà ad eseguire. L'idea è che nella realtà
l'umano non ha un comportamento deterministico e quindi si devono
prendere in considerazioni tutte le sue azioni possibili; questa diventa
la parte interessante dell'analisi con \texttt{scl} , in quanto si cerca
di capire che comportamento sarà più vantaggioso per l'umano. Inoltre
per gli umani è necessario definire i comandi iniziali, che descrivono
il loro comportamento e le loro interazioni con gli altri attori della
configurazione.

Anche se non era prevista una vera e propria sintassi, all'inizio di
questa tesi era già prevista una struttura per l'albero di sintassi
astratta tipato in \texttt{scl} (era infatti implementato in OCaml con i
GADT). Ho implementato facilmente il parser avendo come albero di
sintassi astratta in output direttamente queste strutture, senza passare
per una struttura intermedia. Si ha avuto quindi un minor sforzo nella
fase di implementazione, avendo comunque il vantaggio di non
preoccuparsi di incorrere in errori di tipo durante il parsing, dal
momento che la stessa struttura in output garantisce che il programma in
input sia ben tipato.

\hypertarget{sintassi-per-scl}{%
\section{\texorpdfstring{Sintassi per
\texttt{scl}}{Sintassi per scl}}\label{sintassi-per-scl}}

Il parser verso \texttt{scl} deve costruire l'albero di sintassi
astratta del testo in input, basandosi sulla sua grammatica specifica,
la quale necessita di essere definita:

\begin{verbatim}
configuration ::= act*
act ::= (Human | Contract) ('(' Int ')')? '{' decl* meth* '}'
stm ::= decl | Var '=' rhs | 'if' bexpr 'then' stm 'else' stm | stm stm 
        | stm '+' stm | '{' stm '}'
decl ::= t Var ('=' v)?
meth ::=  'function' Var '('(t Var (',' t Var)*)? '):' t '{' stm 'return' e '}'
rhs ::= e | (cexpr '.')? Var ('.' value '(' iexpr ')')? '(' (e (',' e)*)? ')'
v ::= Int | Bool | String 
Bool ::= 'true' | 'false' 
iexpr ::= Int | Var | 'fail' | iexpr? '-' iexpr | iexpr '+' iexpr 
        | Int '*' iexpr | max '(' iexpr ',' iexpr ')' | symbol '(' String ')' | '(' iexp ')'
bexpr ::= Bool | Var | 'fail' | iexpr '>' iexpr | iexpr '>=' iexpr 
        | iexpr '<' iexpr | iexpr '<=' iexpr | e '==' e | '!' bexpr 
        | bexpr '&&' bexpr | bexpr '||' bexpr | '(' bexpr ')'  
sexpr ::= String | Var | 'fail'
cexpr ::= this | Var | 'fail | contr_addr '(' String ')'
hexpr ::= Var | fail | hum_addr '(' String ')'
e ::= iexpr | bexpr | sexpr | cexpr | hexpr 
t ::= int | bool | string | Contract | Human
\end{verbatim}

In figura viene mostrata la grammatica su cui si basa l'analizzatore
sintattico, nella quale sono presenti i simboli terminali che
necessitano di essere riconosciuti durante l'analisi lessicale: che sono
\texttt{Int} (ovvero l'insieme dei numeri interi), \texttt{String}
(l'insieme delle stringhe) e \texttt{Var} (l'insieme di tutte le
variabili), a cui si aggiungono tutte le parole chiave (ad esempio
\texttt{return}, \texttt{if}, \texttt{+}, \texttt{\textgreater{}},
\ldots{}) che devono essere specificate al lexer. Invece la parte di
analisi sintattica, una volta riconosciuti i simboli terminali, si
preoccuperà di riconoscere i simboli non terminali e le opportune
produzioni ricalcando la struttura del programma in input.

Questa sintassi permette di definire un insieme di attori, ognuno dei
quali ha sia dei campi, che devono essere dichiarati, che una lista di
metodi. Questi ultimi sono composti da una \emph{signature} (con tipo in
input e in output, dove quest'ultimo è sempre presente), uno statement
(consistente in una lista di comandi di assegnamento, o istruzione
condizionale o, nel caso di attori umani, scelta) e espressione di
ritorno. I tipi nella grammatica sono gli stessi tipi di \texttt{scl}:
interi, booleani, stringhe, contratti e umani. Sono messe a disposizione
le principali operazioni tra questi in particolar modo per gli interi e
per i booleani. È possibile anche assegnare una stringa a un intero
tramite il costrutto \texttt{symbol}, che similmente alle macro di C
indica un valore costante.

Particolarmente interessante è il fatto che nella dichiarazione
dell'attore si può specificare tra \texttt{()} il \emph{balance}
iniziale, ovvero la quantità di criptovaluta che è inizialmente
assegnata al contratto o all'umano. Questo equivale a fare un
assegnamento alla variabile intera denominata \texttt{balance}. È
inoltre possibile inviare dei quantitativi di criptovaluta al contratto
nelle chiamate di funzioni semplicemente con la parola chiave
\texttt{value} e specificando il valore.

Si può facilmente notare che la grammatica scelta è ambigua, come viene
mostrato in questo breve esempio di un assegnamento: \texttt{x\ =\ y}
che si sviluppa a partire dal non terminale \texttt{stm}

\begin{verbatim}
stm -> Var = rhs -> x = rhs -> x = e
\end{verbatim}

uno statement, quindi diventa un assegnamento di un'espressione a una
variabile. L'espressione ora ha può avere due produzioni:

\textbf{Caso 1:} l'espressione generica diventa un'espressione intera

\begin{verbatim}
x = iexpr -> x = y
\end{verbatim}

\textbf{Caso 2:} l'espressione generica diventa un'espressione booleana

\begin{verbatim}
x = bexpr -> x = y
\end{verbatim}

Si è visto che in entrambi i casi si è prodotta la stessa sequenza
partendo dallo stesso non terminale, ma con derivazioni diverse.
L'ambiguità è quindi dovuta al fatto che diversi non terminali
(tipicamente relativi alle espressioni) possono accettare
indistintamente delle variabili a prescindere dal loro tipo. È
necessario quindi che il parser quando incorre nel riconoscimento di una
variabile riconosca direttamente il suo tipo. Successivamente si vedrà
come viene affrontato il problema.

\hypertarget{eliminazione-ricorsione-sinistra}{%
\section{Eliminazione ricorsione
sinistra}\label{eliminazione-ricorsione-sinistra}}

Come si nota la grammatica, oltre a essere ambigua è anche ricorsiva
sinistra, mostriamo soltanto il caso dell'eliminazione della ricorsione
sinistra nel non terminale \texttt{iexpr} (connotazione per le
espressioni intere), per gli altri non terminali la risoluzione è
analoga. L'idea usata è quella di sostituire al non terminale due non
terminali: il primo con tutte e sole regole senza ricorsione sinistra il
secondo con le regole in cui questa è presente. I due non terminali
vengono rispettivamente \texttt{atomic\_iexpr} e \texttt{cont\_iexpr}, e
vengono definiti in questo modo:

\begin{verbatim}
atomic_iexpr ::= Int | Var | fail | '-' iexpr | max '(' iexpr ',' iexpr ')'
                | symbol string | '(' iexpr ')'
cont_iexpr ::= '+' iexpr | '-' iexpr | '*' iexpr 
\end{verbatim}

In questo esempio \texttt{atomic\_iexpr} rappresenta un non terminale
per alcune espressioni intere (appunto quelle atomiche), mentre
\texttt{cont\_iexpr} considerato singolarmente non ha alcuna valenza:
deve essere concatenato a un'espressione intera, che sarà quindi
\texttt{atomic\_iexpr}. Il non terminale \texttt{iexpr} verrà costruito
concatenando i due non terminali appena prodotti. Avrà quindi la
seguente definizione:

\begin{verbatim}
iexpr ::= atomic_iexpr (cont_iexpr)?
\end{verbatim}

\hypertarget{albero-di-sintassi-astratta}{%
\section{Albero di sintassi
astratta}\label{albero-di-sintassi-astratta}}

Dopo aver definito la grammatica mostriamo l'albero di sintassi astratta
generato come output dal parser, che rappresenterà la struttura logica
del programma in input. In figura viene mostrato il tipo di ritorno per
la grammatica della figura precedente.

\begin{verbatim}
configuration ::= {contract: a_contract list, human: a_human list}
a_contract ::= (Contract string, meth list, decl list)
a_human ::= (Human string, meth list, decl list, stack)
stack ::= Return (t,e) | SComp(Stm stm, stack)
stm ::= Assign (var,e) | IfThenElse (e,stm,stm) | Comp (stm,stm) |
        Choice(stm,stm)
decl ::= Let((t,string),v)
program ::= meth,(vlist,stm,e)
meth ::= (t,tlist,string)
rhs ::= Expr e | Call (e,meth,elist) | CallWithValue (e,meth,elist,int)
var ::= (t,string)
v ::= int | bool | string | Contract string | Human string
e ::= Value v | Var var | Fail | This | Field var |
      Plus (e,e) | Mult (e,e) | Minus e | Max(e,e) | Geq(e,e)
      | Gt(e,e) | Eq(t,e,e) | And(e,e) | Or (e,e) | Not e |
      Symbol string
elist ::= ENil | ECons (e,elist)
tlist ::= TNil | TCons (t,tlist)
vlist ::= VNil | VCons (var,vlist)

t ::= Int | Bool | String | ContractAddress | HumanAddress
\end{verbatim}

Come si può notare la grammatica definita precedentemente rimane molto
conforme all'albero di sintassi astratta. Infatti ai simboli non
terminali della grammatica sono fatti corrispondere i nodi dell'albero,
e ai simboli terminali invece sono fatte corrispondere le foglie: si può
quindi presupporre che ci sia una certa associazione tra albero di
sintassi astratta e grammatica. Ciò che deve fare il parser è avendo un
testo in input, in un primo luogo riconoscere passo per passo il testo
nella grammatica, e nel mentre, sulla base di questa associazione
costruire l'albero di sintassi astratta.

\hypertarget{conclusione-1}{%
\section{Conclusione}\label{conclusione-1}}

È stata presentata la grammatica del parser, anche se è ancora
necessario risolvere il problema dell'ambiguità. Per come si presenta il
problema, l'ambiguità è possibile eliminarla a livello d'implementazione
del parser: infatti sarà sufficiente attribuire ad ogni variabile il suo
tipo, in modo che ad ogni occorrenza della variabile sia chiaro a che
regola della grammatica questa faccia parte. Siccome è stata definita la
struttura dell'input (ovvero la grammatica del linguaggio) e la
struttura dell'output (ovvero la struttura dell'AST) possiamo procedere
per la descrizione dell'implementazione.

\newpage

\hypertarget{parsing}{%
\chapter{Parsing}\label{parsing}}

\hypertarget{introduzione-3}{%
\section{Introduzione}\label{introduzione-3}}

In questa sezione ci si concentra sull'implementazione del parser verso
\texttt{scl}. Vengono quindi descritte le tecniche e le scelte
implementative che portano il parser a prendere in input una lista di
caratteri e determinarne la correttezza basandosi sulla grammatica,
generando quindi il relativo albero di sintassi astratta per tale lista.

Il parser in considerazione è implementato in OCaml, questa scelta
risulta abbastanza ovvia dal momento che lo stesso \texttt{scl} è
implementato in questo linguaggio.

\hypertarget{analisi-lessicale}{%
\section{Analisi lessicale}\label{analisi-lessicale}}

È conveniente che il parser non faccia l'analisi sintattica direttamente
sul testo in input: per iniziare è meglio che abbia in ingresso una
sequenza di token. Ogni token è una coppia nome-valore, dove il nome
rappresenta una determinata categoria sintattica, mentre il valore è una
stringa del testo. Quindi per generare i token si inizia facendo
l'analisi lessicale, dividendo le stringhe in input in diverse categorie
(le categorie sintattiche, appunto).

Con questo obiettivo si è usato il modulo \texttt{Genlex} di OCaml, che
permette di generare un analizzatore lessicale che in OCaml consiste in
una funzione che prende in input uno stream di caratteri e restituisce
in output una lista di token. Inoltre questo strumento è particolarmente
vantaggioso rispetto a un'analisi lessicale costruita da zero, perché
toglie la preoccupazione di fornire un'implementazione per l'aggiunta di
commenti nel testo, così come diventa automatica la rimozione degli
spazi bianchi tra le varie stringhe. I token quindi sono riconosciuti e
ad ognuno di essi è associato una categoria (o nome). Le possibili
categorie sono: interi, stringhe, identificativi e parole chiave. Mentre
interi, stringhe e identificativi sono già noti al lexer, perché sono
caratteristici di tutti i linguaggi, le parole chiave richiedono di
essere esplicitate, perché sono specifiche del lessico del linguaggio di
cui fare il parsing.

Concettualmente l'analizzatore sintattico richiederebbe uno stream di
token, quindi ci si aspetterebbe che il parser implementato richieda un
input del tipo \texttt{token\ Stream.t}. Infatti il tipo \texttt{Stream}
di OCaml offrirebbe un vantaggio in termini di memorizzazione: non è
necessario che tutta la sequenza di token sia in memoria, e sebbene
l'analizzatore lessicale generato da \texttt{make\_lexer} --la funzione
di \texttt{GenLex} che lo genera-- restituisca un tipo
\texttt{token\ Stream.t}, è stato scelto di usare una lista di token.
Questa è stata una scelta di natura implementativa: come sarà più chiaro
successivamente, il parser ha bisogno di fare backtracking, e con gli
\texttt{Stream} di OCaml l'operazione diventerebbe ardua siccome
l'eliminazione di un elemento sarebbe distruttiva. Con la lista in(con
codice scl)vece l'iterazione è molto più semplice e si può procedere in
entrambe le direzioni senza preoccupazione.

L'analisi lessicale, quindi, relativamente alla grammatica consiste nel
riconoscere i simboli terminali come tali, in modo che successivamente
ci si concentri separatamente nel riconoscimento delle produzioni della
grammatica.

\hypertarget{implementazione-con-parser-combinator}{%
\section{Implementazione con parser
combinator}\label{implementazione-con-parser-combinator}}

Una volta definita la grammatica e riconosciuti i simboli terminali di
questa si hanno tutte le basi necessarie per l'implementazione OCaml del
parser. Il parser può essere implementato con diverse tecniche:
similmente a quanto fatto per l'analisi lessicale si potrebbero usare
librerie di parsing che generano analizzatori sintattici, oppure si
potrebbe usare la tecnica del parser combinator. In questo caso è stata
preferita quest'ultima tecnica, che consiste nel considerare un parser
come una funzione di ordine superiore che avendo uno o più parser in
input restituisce un nuovo parser (da qui il nome). A livello di codice
per parser si intende una funzione che prende una lista di token e
restituisce l'albero di derivazione e la lista dei token rimanenti.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{type}\NormalTok{ 'ast }\KeywordTok{parser}\NormalTok{ = }
\NormalTok{token t -> (vartable * }\DataTypeTok{bool}\NormalTok{) -> token t * 'ast * (vartable * }\DataTypeTok{bool}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Per l'implementazione è necessario definire un'eccezione che ogni
funzione \texttt{parser} solleverà qualora non dovesse essere in grado
di riconoscere l'input, questa eccezione è stata denominata
\texttt{Fail}.

Con l'ausilio dei parser combinator si possono tradurre facilmente le
produzioni della grammatica definita in precedenza: innanzitutto è
necessario descrivere gli operatori sintattici necessari, ovvero la
concatenazione, la stella di Kleene, l'unione, la costante e l'operatore
possibilità. L'implementazione di ogni operatore risulta semplice: ad
ognuno di questi è fatta corrispondere una funzione, che nella logica
dei parser combinator genera un nuovo parser specifico per l'operatore
in questione. Questi parser verranno poi composti tra loro, secondo le
regole della grammatica, per riuscire a riconoscere una qualsiasi
produzione.

Per l'operatore costante --che riconosce i simboli terminali-- viene
generato un parser che verifica se il simbolo richiesto corrisponde al
simbolo in input: nel caso in cui questo succeda l'input può essere
consumato:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ const : token -> (token -> 'ast) -> 'ast }\KeywordTok{parser}\NormalTok{ =}
 \KeywordTok{fun}\NormalTok{ t1 f t2 tbl ->}
  \KeywordTok{if}\NormalTok{ (}\DataTypeTok{List}\NormalTok{.length t2 > }\DecValTok{0}\NormalTok{) && (t1 = (}\DataTypeTok{List}\NormalTok{.hd t2)) }\KeywordTok{then}
\NormalTok{   (junk t2), f t1, tbl}
  \KeywordTok{else}
   \DataTypeTok{raise}\NormalTok{ Fail}
\end{Highlighting}
\end{Shaded}

Per l'operatore di unione sono necessari due parser in input. Per
implementare l'idea di scelta non deterministica viene eseguito il primo
parser: nel caso questo sollevi \texttt{Fail} facendo backtracking viene
eseguito il parser rimanente:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ choice : 'ast }\KeywordTok{parser}\NormalTok{ -> 'ast }\KeywordTok{parser}\NormalTok{ -> 'ast }\KeywordTok{parser}
\NormalTok{= }\KeywordTok{fun}\NormalTok{ p1 p2 s tbl ->}
 \KeywordTok{try}\NormalTok{ p1 s tbl }\KeywordTok{with}\NormalTok{ Fail -> p2 s tbl}
\end{Highlighting}
\end{Shaded}

La concatenazione invece consiste nel prendere in input due parser e
eseguirli sequenzialmente unendo successivamente i due output:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ concat : }
\NormalTok{'ast1 }\KeywordTok{parser}\NormalTok{ -> 'ast2 }\KeywordTok{parser}\NormalTok{ -> ('ast1 -> 'ast2 -> 'ast3) -> 'ast3 }\KeywordTok{parser}\NormalTok{ = }
\KeywordTok{fun}\NormalTok{ p1 p2 f s tbl ->}
  \KeywordTok{let}\NormalTok{ rest1,ast1,tbl1 = p1 s tbl }\KeywordTok{in}
  \KeywordTok{let}\NormalTok{ rest2,ast2,tbl2 = p2 rest1 tbl1 }\KeywordTok{in}
\NormalTok{  rest2,f ast1 ast2,tbl2}
\end{Highlighting}
\end{Shaded}

La stella di Kleene vede l'esecuzione dello stesso parser finché questo
non solleva \texttt{Fail} --caso per cui l'esecuzione dell'operatore
termina:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ kleenestar : }
\NormalTok{'ast2 }\KeywordTok{parser}\NormalTok{ -> 'ast1 -> ('ast1 -> 'ast2 -> 'ast1) -> 'ast1 }\KeywordTok{parser}\NormalTok{ =}
 \KeywordTok{fun}\NormalTok{ p empty_ast f s t ->}
  \KeywordTok{let} \KeywordTok{rec}\NormalTok{ aux p1 s1 acc tbl=}
  \KeywordTok{try}
   \KeywordTok{let}\NormalTok{ (rest1, ast1, ntbl) = p1 s1 tbl }\KeywordTok{in}
\NormalTok{   aux p1 rest1 (f acc ast1) ntbl}
  \KeywordTok{with}\NormalTok{ Fail -> (s1, acc, tbl)}
  \KeywordTok{in}\NormalTok{ aux p s empty_ast t}
\end{Highlighting}
\end{Shaded}

Per concludere, l'operatore di possibilità corrisponde un parser che
semplicemente prevede che possa fallire:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \DataTypeTok{option}\NormalTok{ : 'ast }\KeywordTok{parser}\NormalTok{ -> 'ast }\DataTypeTok{option} \KeywordTok{parser}\NormalTok{ =}
 \KeywordTok{fun}\NormalTok{ p s tbl -> }\KeywordTok{try}
  \KeywordTok{let}\NormalTok{ next,res,ntbl = p s tbl }\KeywordTok{in}\NormalTok{ next,}\DataTypeTok{Some}\NormalTok{ res,ntbl}
 \KeywordTok{with}\NormalTok{ Fail -> s,}\DataTypeTok{None}\NormalTok{,tbl}
\end{Highlighting}
\end{Shaded}

Dopo aver definito questi operatori diventa banale scrivere il parser.
Ad ogni non terminale della grammatica viene costruita una nuova
funzione di tipo \texttt{parser}, costituita dalla corretta composizione
delle funzioni di parsing appena descritte, coerentemente con quanto
definito dalle regole della grammatica. Degli esempi li si avranno
successivamente.

Mostriamo di seguito l'esempio relativo al parsing del non terminale
\texttt{iexpr}, dopo aver eliminato la ricorsione sinistra come abbiamo
visto

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{rec}\NormalTok{ atomic_int_expr s =}
\NormalTok{ choice_list [}
\NormalTok{   comb_parser (base Int) (}\KeywordTok{fun}\NormalTok{ expr -> AnyExpr(Int,expr));}
\NormalTok{   concat (kwd }\StringTok{"-"}\NormalTok{) atomic_int_expr (}\KeywordTok{fun}\NormalTok{ _ -> minus) ;}
\NormalTok{   concat (concat (kwd }\StringTok{"("}\NormalTok{) int_expr scd) (kwd }\StringTok{")"}\NormalTok{) }\DataTypeTok{fst}\NormalTok{ ;}
\NormalTok{   concat (concat (kwd }\StringTok{"max"}\NormalTok{) int_expr scd) int_expr }\DataTypeTok{max}\NormalTok{;}
\NormalTok{   concat (kwd }\StringTok{"symbol"}\NormalTok{) symbol_pars scd;}
\NormalTok{ ] s}
\KeywordTok{and}\NormalTok{ int_expr s =}
\NormalTok{ concat atomic_int_expr (}\DataTypeTok{option}\NormalTok{ cont_int_expr)}
\NormalTok{ (}\KeywordTok{fun}\NormalTok{ x f -> }\KeywordTok{match}\NormalTok{ f }\KeywordTok{with} \DataTypeTok{Some}\NormalTok{ funct -> funct x | _ -> x) s}
\KeywordTok{and}\NormalTok{ binop s =}
\NormalTok{ choice_list [}
\NormalTok{  const (Kwd }\StringTok{"+"}\NormalTok{) (}\KeywordTok{fun}\NormalTok{ _ -> plus) ;}
\NormalTok{  const (Kwd }\StringTok{"*"}\NormalTok{) (}\KeywordTok{fun}\NormalTok{ _ -> mult) ;}
\NormalTok{  const (Kwd }\StringTok{"-"}\NormalTok{) (}\KeywordTok{fun}\NormalTok{ _ -> subtract)}
\NormalTok{ ] s}
\KeywordTok{and}\NormalTok{ cont_int_expr s = concat binop int_expr (}\KeywordTok{fun}\NormalTok{ f x -> f x) s}
\end{Highlighting}
\end{Shaded}

Si è quindi spiegato come il parser riesce a riconoscere la grammatica e
si è visto che le funzioni per gli operatori sintattici implementati con
la logica dei parser combinator prendono in input funzioni per la
costruzione dell'albero di sintassi astratta.

\hypertarget{costruzione-dellalbero-di-sintassi-astratta}{%
\section{Costruzione dell'albero di sintassi
astratta}\label{costruzione-dellalbero-di-sintassi-astratta}}

Come spiegato nel capitolo precedente
(\ref{albero-di-sintassi-astratta-di-ritorno}) tra la grammatica e
l'albero di sintassi astratta per tale grammatica si ha un'associazione
abbastanza diretta, quindi mentre si riconduce il testo alle produzioni
della grammatica è abbastanza immediato costruire l'albero relativo. A
titolo di esempio vediamo come nel caso atomico, una volta riconosciuto
il token sia abbastanza immediato costruire la foglia:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ value : }\KeywordTok{type}\NormalTok{ a. a tag -> token -> a expr = }\KeywordTok{fun}\NormalTok{ tag tok ->}
 \KeywordTok{match}\NormalTok{ tag,tok }\KeywordTok{with}
\NormalTok{ | }\DataTypeTok{String}\NormalTok{,}\DataTypeTok{Genlex}\NormalTok{.}\DataTypeTok{String}\NormalTok{ x -> Value x}
\NormalTok{ | Int,Int x -> Value x}
\NormalTok{ | Bool,Kwd }\StringTok{"true"}\NormalTok{ -> Value }\KeywordTok{true}
\NormalTok{ | Bool,Kwd }\StringTok{"false"}\NormalTok{ -> Value }\KeywordTok{false}
\NormalTok{ | _ -> }\DataTypeTok{raise}\NormalTok{ Fail}

\KeywordTok{let}\NormalTok{ value_pars tag s = const (}\DataTypeTok{List}\NormalTok{.hd s) (value tag) s}
\end{Highlighting}
\end{Shaded}

Nell'esempio \texttt{value\_pars} è il parser per il non terminale
\texttt{v} della grammatica. Si tratta infatti semplicemente di passare
dalla lista di token a un'espressione in \texttt{scl}. Si noti che
\texttt{Value} è un costrutto dell'AST di \texttt{scl}.

Nel caso non atomico, ovvero durante la costruzione di un nodo
dell'albero, dal momento che due \texttt{parser} sono combinati è
necessario fare un controllo sul tipo. È vero che essendo l'albero di
sintassi astratta una \emph{Intrinsically Typed Data Structure} non si
può incorre in problemi di tipo, tuttavia al momento della costruzione
della struttura è necessario fare il \emph{type checking} in modo che i
costruttori del GADT abbiano la certezza che i tipi combacino. In
\texttt{scl}, ad esempio, il costruttore per l'assegnamento è definito
in questo modo:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{type}\NormalTok{ stm =}
\NormalTok{ | Assign : 'a field * 'a rhs -> stm}
\NormalTok{ | ...}
\end{Highlighting}
\end{Shaded}

Quindi una volta che si ha un \texttt{field} e un \texttt{rhs}, per
costruire il relativo \texttt{Assign} è necessario controllare che
\texttt{field} e \texttt{rhs} abbiano lo stesso tipo. Sempre secondo la
logica dei GADT, poiché permette di definire una \emph{Intrinsically
Typed Data Structure} definiamo il tipo delle prove di uguaglianza di
due tipi:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{type}\NormalTok{ (_,_) eq = Refl : ('a,'a) eq}
\end{Highlighting}
\end{Shaded}

Usando questo particolare tipo possiamo implementare una funzione che
permetta il cast tra due tipi:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ eq_tag : }\KeywordTok{type}\NormalTok{ a b. a tag -> b tag -> (a,b) eq }\DataTypeTok{option}\NormalTok{ = }\KeywordTok{fun}\NormalTok{ t1 t2 ->}
 \KeywordTok{match}\NormalTok{ t1,t2 }\KeywordTok{with}
\NormalTok{ | Int, Int -> }\DataTypeTok{Some}\NormalTok{ Refl}
\NormalTok{ | Bool, Bool -> }\DataTypeTok{Some}\NormalTok{ Refl}
\NormalTok{ | }\DataTypeTok{String}\NormalTok{, }\DataTypeTok{String}\NormalTok{ -> }\DataTypeTok{Some}\NormalTok{ Refl}
\NormalTok{ | ContractAddress, ContractAddress -> }\DataTypeTok{Some}\NormalTok{ Refl}
\NormalTok{ | HumanAddress, HumanAddress -> }\DataTypeTok{Some}\NormalTok{ Refl}
\NormalTok{ | _,_ -> }\DataTypeTok{None}
\end{Highlighting}
\end{Shaded}

Nei rami del pattern matching della funzione \texttt{eq\_tag} sono
istanziati i tipi in input, quindi il tipo di ritorno non solo permette
di se i tipi in input combacino, ma restituendo \texttt{Refl} contiene
le istanze stesse dei due tipi. Una volta che si ha a disposizione la
funzione \texttt{eq\_tag} diventa possibile implementare un parser per
l'assegnamento, quindi che generi un \texttt{Assign} combinando il
risultato dei parser che riconoscono \texttt{field} e \texttt{rhs}, e
controllando che il tipo di ritorno dei due parser sia il medesimo:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ assign_pars =}
\NormalTok{ concat (concat field_pars (kwd }\StringTok{"="}\NormalTok{) }\DataTypeTok{fst}\NormalTok{) rhs_pars}
\NormalTok{ (}\KeywordTok{fun}\NormalTok{ (AnyField(tfield,name)) (AnyRhs(trhs,r))-> }
 \KeywordTok{match}\NormalTok{ eq_tag tfield trhs }\KeywordTok{with}
\NormalTok{ | }\DataTypeTok{Some}\NormalTok{ Refl -> Assign((tfield,name),r)}
\NormalTok{ | }\DataTypeTok{None}\NormalTok{ -> }\DataTypeTok{raise}\NormalTok{ Fail)}
\end{Highlighting}
\end{Shaded}

Nell'esempio si ha una funzione \texttt{parser} in cui usando le i
parser combinator degli operatori sintattici è esplicitata la forma
sintattica che deve avere un assegnamento (si veda l'analogia
nell'assegnamento nella grammatica) ed è specificato come viene
costruito l'albero di derivazione. In questo caso \texttt{AnyField} e
\texttt{AnyRhs} sono costrutti che contengono rispettivamente il valore
del campo e del \emph{rhs}, ovviamente con i rispettivi tipi.
Inizialmente questi due tipi, sono due tipi generici, ma attraverso il
pattern matching della funzione \texttt{eq\_tag} sui due tipi nel ramo
\texttt{Refl} si ha l'istanziazione dei due tipi nello stesso generico
tipo, che permette la generazione del nodo \texttt{Assign} nell'albero
sintattico.

Analogamente a quanto è avvenuto in questi due casi può essere costruito
ogni nodo o foglia dell'albero.

Si è quindi visto che con l'ausilio dei parser combinator il parser
generato è top-down, cioè che inizia a costruire l'albero dalla radice.
Per iniziare definisce una \emph{configuration} vuota (il simbolo
iniziale) che verrà riempita dall'attività dell'analizzatore sintattico.
In questo tipo di parsing l'input viene consumato da sinistra a destra
con solo un simbolo di lookahead -- che se non viene riconosciuto
implica il backtracking. Sebbene il parsing abbia i requisiti per essere
di tipo LL(1) la grammatica in realtà non lo è. Questo perché, come
visto in precedenza, presenta delle ambiguità.

\hypertarget{controllo-dei-tipi-e-tabella-dei-simboli}{%
\section{Controllo dei tipi e tabella dei
simboli}\label{controllo-dei-tipi-e-tabella-dei-simboli}}

Le ambiguità della grammatica, stando alla sua definizione, sono dovute
al fatto che in non terminali che connotano espressioni di tipo diverso
può comparire la stessa variabile. Per eliminare l'ambiguità è
necessario, quindi, che in ogni espressione se è presente una variabile
già si conosca il tipo di quest'ultima. Questo obiettivo può essere
conseguito in due modi: o ad ogni occorrenza della variabile si
specifica sia il tipo che il nome, oppure si specifica solo il nome
della variabile ma si fa in modo che il parser possa leggere il tipo di
dato in una tabella apposita (in cui è associata ad ogni nome di
variabile il suo tipo). Siccome si preferisce che solo il nome sia
identificativo univoco per la variabile (come avviene in quasi tutti i
linguaggi di programmazione) si sceglie la seconda opzione. Di
conseguenza all'interno del programma su cui effettuare il parsing non
potranno mai esistere due variabili diverse ma con lo stesso tipo, cosa
che in realtà è possibile nella struttura degli attori in \texttt{scl}.
Così facendo si ha una perdita di espressività minima, ma si ha il
vantaggio di favorire una programmazione più consapevole.

La tabella è quindi relativa a un singolo attore, e contiene la lista
delle coppie tipo-nome di tutte le sue variabili. Essendo OCaml un
linguaggio funzionale, non può essere che la tabella sia una variabile
globale, altrimenti non potrebbe essere modificabile. È necessario
quindi che la stessa funzione di tipo \texttt{parser} richieda in input
e restituisca in output la tabella, in modo tale che gli sia consentito
aggiungere o rimuovere elementi. In particolare una nuova variabile deve
essere aggiunta alla tabella quando viene dichiarata, e quando si ha un
assegnamento di una variabile non ancora presente in tabella. Ad ogni
aggiunta viene controllata la tabella e nel caso fosse già presente una
variabile con lo stesso nome, il parser solleva \texttt{Fail} e termina
la sua esecuzione. Invece ad ogni occorrenza della variabile viene fatta
sempre una ricerca nella tabella per conoscerne il tipo.

Le variabili oltre a poter essere aggiunte alla tabella devono anche
poter essere rimosse. Si prenda in considerazione una variabile locale
all'interno di una funzione: essa non deve essere visibile in
nessun'altra funzione esterna. Quando verrà quindi fatto successivamente
il parsing di un'altra funzione, se questa seconda funzione presenta una
variabile con lo stesso nome questa non dovrà essere presente nella
tabella. Diventa allora necessario definire lo scope per le variabili,
in modo che determini la presenza o meno della variabile nella tabella.
Per come è definito il linguaggio questa è un'operazione banale, infatti
in \texttt{scl} non ci sono funzioni annidate, quindi gli unici blocchi
di cui può far parte una variabile sono il blocco globale dell'attore e
il blocco locale della funzione. Quindi, durante il parsing, o la
variabile è una variabile globale o è una variabile locale della
funzione presa in esame: non è possibile avere una variabile attiva che
sia allo stesso tempo variabile locale di un'altra funzione. Quindi
basta associare ad ogni variabile nella tabella un valore booleano che
denota se la variabile è locale o meno, per far sì che quando venga
finito il parsing di una funzione tutte le variabili locali vengano
rimosse.

Analogamente alle variabili anche le funzioni possono essere aggiunte
nella stessa tabella: quando viene dichiarato un metodo, la
\emph{signature} di questo --nome, lista dei tipi dei parametri e tipo
di ritorno-- viene salvata nella tabella dell'attore. Così, ogni volta
che ci sarà una chiamata di funzione, dal nome di questa viene cercata
la \emph{signature} del metodo nella tabella, e si verifica che la lista
delle espressioni nella chiamata sia coerente con la lista dei parametri
presa dalla \emph{signature} appena ritornata. In \texttt{scl} però si
possono chiamare i metodi di uno specifico contratto, in questo caso non
verrà fatto alcun controllo perché il contratto potrebbe essere esterno
al testo su cui fare il parsing e, in questo caso, non si avrebbe
nessuna informazione.

Un'altra informazione che il parser deve conoscere durante la sua
esecuzione è se l'attore che sta analizzando sia umano o contratto: come
si è visto prima all'umano sono permessi più comandi e quindi il suo
codice può presentare diversi comandi. Questa informazione, che si
traduce in un booleano, è affiancato alla tabella come input e output di
ogni funzione di tipo \texttt{parser}.

\hypertarget{conclusione-2}{%
\section{Conclusione}\label{conclusione-2}}

Si è quindi visto che per il parser LL(1) implementato è stato
necessario definire in primo luogo una sintassi per \texttt{scl}. Con la
tecnica dei parser combinator poi è bastato trascrivere le stesse regole
della grammatica come combinazione di più parser, facendo però alcuni
accorgimenti: si è tolta la ricorsione sinistra per evitare che il
parser divergesse. Grazie all'uso dei GADT a livello di implementazione
del parser, si è poi fatto in modo che il parsing si concluda con
successo solamente se c'è concordanza tra i tipi effettivamente usati
nelle espressioni con la grammatica che definisce le espressioni stesse.

Il problema dell'ambiguità della grammatica, invece, è stato aggirato
mediante la creazione di una tabella che permettesse di ricordare
l'associazione tra nome di variabile e tipo per tutta la durata del
parsing.

\newpage

\hypertarget{compilazione}{%
\chapter{Compilazione}\label{compilazione}}

\hypertarget{introduzione-4}{%
\section{Introduzione}\label{introduzione-4}}

Una volta che si hanno a disposizione tutti gli strumenti per
programmare in \texttt{scl} ci si accorge che ciò che viene a mancare è
un'esecuzione vera e propria del codice su una blockchain: \texttt{scl}
fornisce tutti i mezzi per fare analisi, ma solo con \texttt{scl} non è
possibile fare il deploy di ciò che si scrive. È necessario quindi un
compilatore da \texttt{scl} verso un linguaggio già conosciuto, che
dovrà essere un linguaggio di \emph{smart contract}. Si è scelto
Solidity, principalmente per il fatto che è il più conosciuto e, a
differenza di altri (come ad esempio Liquidity), allo stato attuale è
difficile che venga abbandonato. Con Solidity diventa possibile fare il
deploy dei contratti sulla sua blockchain Ethereum.

Il processo di compilazione verso Solidity si divide in due parti: la
prima in cui dall'albero di sintassi astratta \texttt{scl} si passa a un
altro albero di sintassi astratta per Solidity; la seconda in cui
l'albero generato viene tradotto in effettivo codice Solidity.

\hypertarget{solidity-ed-ethereum}{%
\section{Solidity ed Ethereum}\label{solidity-ed-ethereum}}

Ethereum è una piattaforma decentralizzata che permette lo sviluppo di
\emph{smart contract} da parte di programmatori. Ethereum mette a
disposizione Solidity, un linguaggio che in una logica di programmazione
ad oggetti class-based permette di programmare \emph{smart contract}. Il
compilatore di Solidity traduce in un primo momento il programma in
bytecode per poi eseguirlo nella EVM, la macchina virtuale di Ethereum
-- la quale costituisce, quindi, l'ambiente di esecuzione degli
\emph{smart contract}.

Solidity è un linguaggio imperativo che permette di definire delle
classi di contratti, che come nella logica dei linguaggi orientati agli
oggetti possono essere ereditati da altre classi o interfacce,
specificando metodi e campi. Ogni contratto nella blockchain ha un suo
indirizzo specifico a cui altri contratti si possono riferirsi. Inoltre
tutti i contratti hanno un campo \texttt{balance} che consiste nella
quantità di Ether (criptovaluta di Ethereum) che può essere modificato
con transazioni (chiamate di funzioni) da parte di utenti o contratti.
Le funzioni possono essere marcate come \texttt{payable}, in modo tale
da poter ricevere Ether quando chiamate. Ci sono poi indirizzi speciali
come il noto \texttt{this} e \texttt{msg.sender}, dove quest'ultimo si
riferisce all'indirizzo al chiamato. Ogni contratto inoltre ha un
Abstract Binary Interface (\texttt{ABI}) che rappresenta l'interfaccia
di un contratto, costituita dalle firme dei metodi e dai campi del
contratto. L'\texttt{ABI} diventa interessante nella fase di deploy, in
quanto con l'indirizzo del contratto costituisce l'insieme delle
informazioni necessarie per la creazione del contratto stesso. Solidity
permette di riferirsi a un indirizzo di un contratto tramite la parola
chiave \texttt{address}, che costituisce il tipo generico di un oggetto
(analogamente a \texttt{Object} in Java), e che diventa utile in fase di
compilazione nell'eventualità ci si debba riferire a un contratto non
conosciuto. Ogni contratto può definire una funzione di
\texttt{fallback}, che viene eseguita quando dall'esterno ci si
riferisce a una funzione non presente nell'\texttt{ABI} del contratto
stesso.

Solidity quindi definisce solo i contratti, non mette a disposizione gli
strumenti per definire gli utenti: infatti chi vuole interagire coi
contratti di Ethereum deve iscriversi al servizio. Quindi nella
compilazione che si va ad esporre verrà tralasciato l'aspetto relativo
agli utenti.

\hypertarget{differenze-tecniche-tra-scl-e-solidity}{%
\section{\texorpdfstring{Differenze tecniche tra \texttt{scl} e
Solidity}{Differenze tecniche tra scl e Solidity}}\label{differenze-tecniche-tra-scl-e-solidity}}

È stata appena introdotta una differenza importante tra \texttt{scl} e
Solidity: il primo linguaggio definisce un \emph{oggetto} contratto
(ovvero una singola istanza), mentre il secondo definisce la
\emph{classe} del contratto. È necessario marcare questa differenza
perché in \texttt{scl} nella configurazione di un contratto si possono
fare riferimenti specifici ad altri contratti. In aggiunta a questo
nella configurazione non c'è un contratto principale, ma tutti i
contratti sono ``sullo stesso piano'': è necessario mantenere una
situazione analoga in Solidity. Non possiamo quindi delegare a un
singolo contratto il compito di creare gli altri. Conseguentemente i
riferimenti specifici agli altri contratti della configurazione non
possono essere creati all'interno di una classe. È quindi necessaria una
fase di deploy in cui tutti i contratti verranno creati sulla
blockchain, fase che verrà approfondita nel capito \ref{deploy}. Al
momento della creazione ad ogni contratto è assegnato un indirizzo, a
cui gli altri contratti potranno fare riferimento.

\hypertarget{albero-di-sintassi-astratta-per-solidity}{%
\section{Albero di sintassi astratta per
Solidity}\label{albero-di-sintassi-astratta-per-solidity}}

Essendo \texttt{scl} un codice minimale, nella fase di compilazione si
genera un sottoinsieme del codice di Solidity: non saranno catturati
tutti i suoi costrutti, ma solo quelli di cui ne fa relativo uso
\texttt{scl}. Nella prima fase del processo di compilazione abbiamo
tradotto un AST di \texttt{scl} in un AST che fedele ai costrutti di
Solidity.

L'albero di sintassi astratta generato dalla compilazione è sempre
intrinsecamente tipato, quindi l'obiettivo è rappresentare la struttura
di un generico programma ben tipato in Solidity. Il compilatore quindi
deve cercare di tradurre un AST intrinsecamente tipato di \texttt{scl}
in un AST intrinsecamente tipato per Solidity. Siccome ad un programma
ben tipato in \texttt{scl} deve corrispondere uno ben tipato di
Solidity, dobbiamo creare tra i due AST una corrispondenza di tipi. Una
volta creata questa corrispondenza ad ogni costrutto \texttt{scl} deve
essere fatto corrispondere il medesimo in Solidity. Come abbiamo visto,
i costrutti \texttt{scl} sono dei costrutti molto comuni ai linguaggi di
programmazione (\emph{if then else}, chiamate e definizioni di funzioni,
operatori algebrici e logici): la traduzione verso solidity di questi
costrutti risulta abbastanza banale.

Come visto nel capitolo i tipi in \texttt{scl} sono gli interi, i
booleani, le stringhe, i contratti e gli umani. I primi tre di questi
tipi sono dei tipi primitivi in Solidity e quindi ad ognuno di questi
può essere fatto corrispondere il relativo tipo. Gli umani invece non
sono presenti in Solidity, ma siccome la compilazione consiste nella
traduzione solo dei contratti il compilatore può sollevare un'eccezione
quando incorre in una traduzione di un umano.

Bisogna invece prestare più attenzione nella traduzione del tipo
contratto. Ovviamente ad ogni contratto definito in \texttt{scl} è fatta
corrispondere una classe di quel contratto, ma come definire gli oggetti
contratto all'interno di una classe è una questione più delicata: in
\texttt{scl} i contratti non si distinguono tra loro, perché mancano di
interfaccia.

\begin{verbatim}
configuration ::= a_contract list
a_contract ::= Contract(string,decl list,program list)
stm ::= Assignment (var,e) | IfElse (e,stm,stm) | Sequence (stm,stm)
decl ::= Declaration((t,string),v)
program ::= meth,(stm,e)
meth ::= (string,paraml,(t,storage?),view*,visibility*)
storage ::= Storage | Memory | Calldata 
paraml ::= PNil | PCons((t,storage?),paraml)
view ::= View | Pure | Payable
visibility ::= External | Public | Internal | Private
intf_id ::= InterfaceId string
var ::= (t,string)
v ::= int | bool | string | intf_id | AddrInt intf_id
e ::= Value v | Var var | This | MsgValue | Balance 
      | CastInterf (intf_id, e) | Addr e | Plus (e,e) 
      | Mult (e,e) | Minus (e,e) | Max(e,e) | Geq(e,e)
      | Gt(e,e) | Eq(t,e,e) | And(e,e) | Or (e,e) | Not e 
      | Symbol string | CondExpr(e,e,e) | Call(e, meth, elist)
elist ::= ExprNil | ExprCons (e,elist)

t ::= Int | Bool | String | Interf | Address
\end{verbatim}

Sebbene non presenti grandi differenze rispetto all'AST per \texttt{scl}
nella definizione dell'AST per Solidity vengono aggiunti nuovi nodi.
Come si può vedere in figura notiamo che nella definizione di funzione
(\texttt{meth}) viene specificato oltre al nome, i parametri e il tipo
di ritorno, la visibilità e la view che sono caratteristiche di
Solidity. La visibilità, come in altri linguaggi di programmazione ad
oggetti, denota chi può chiamare la funzione, mentre la view (più
specifica per Solidity) è relativa alla possibilità che ha la funzione
di cambiare lo stato interno. Come preannunciato la maggior modifica è
relativa ai tipi contratto: non si ha più un unico \texttt{Contract}, ma
si ha sia il tipo \texttt{Interf} che il tipo \texttt{Address} -- e due
nuove espressioni \texttt{CastInterf} e \texttt{Addr}, le quali
permettono il cast tra i due tipi. Questa distinzione di tipi è dovuta
al fatto che, come esposto prima, in Solidity sono realizzate le classi
relative ai contratti \texttt{scl}, ma un contratto con gli altri
contratti della configurazione interagisce mediante l'indirizzo.

\hypertarget{interfacce-per-le-variabili-contract}{%
\section{\texorpdfstring{Interfacce per le variabili
\texttt{Contract}}{Interfacce per le variabili Contract}}\label{interfacce-per-le-variabili-contract}}

Si deve, quindi, riprodurre in Solidity una configurazione in cui tutti
i contratti si conoscono: per cui questi contratti devono poter essere
espressi come campi all'interno di un contratto. In generale si è visto
che in \texttt{scl} esiste il tipo \texttt{Contract}, di conseguenza è
possibile avere variabili di tipo contratto. Il problema diventa,
quindi, come esprimere queste variabili in Solidity, e in particolare
decidere quale possa essere il loro tipo. Logicamente se si volesse
rimanere aderenti al codice \texttt{scl} queste dovrebbero essere di
tipo \texttt{address}. Il problema però è che se ci si riferisce solo
all'indirizzo del contratto allora anche le chiamate di funzione devono
essere fatte sull'indirizzo --sarebbe come fare in Java una chiamata di
metodo su un oggetto di tipo \texttt{Object}. Solidity permette questo
tipo di chiamate a basso livello usando la funzione \texttt{call};
tuttavia il loro tipo di ritorno è espresso in byte e per fare la
conversione saremmo obbligati a scrivere codice Assembly. Abbiamo,
quindi, preferito un'altra tecnica, dove le chiamate possano essere
fatte su degli oggetti meno generici e dove si conosca il tipo di
ritorno delle funzioni.

Ad ogni campo di tipo contratto allora abbiamo fatto corrispondere
un'interfaccia che contiene la \emph{signature} dei suoi metodi.
Solidity permette appunto di fare il cast da interfaccia a indirizzo e
viceversa. In questo modo è necessario lavorare sia con gli indirizzi
dei contratti, riuscendo a rimanere fedeli al codice \texttt{scl}, e
allo stesso tempo usare le interfacce, necessarie per le chiamate di
funzione. In particolare abbiamo scelto che i campi (sempre di tipo
contratto) siano oggetti che abbiano come tipo la loro interfaccia, e
che i parametri siano indirizzi. Nel momento della loro dichiarazione
assoceremo al parametro la sua relativa interfaccia. Conseguentemente se
si ha una chiamata di funzione su un parametro, di questo verrà fatto il
cast alla sua interfaccia; mentre se viene passato un oggetto di tipo
interfaccia come parametro attuale di una funzione, di questo viene
fatto il cast verso l'indirizzo. È necessario che ad ogni chiamata di un
metodo di un contratto, venga aggiunta la \emph{signature} del metodo
nell'interfaccia.

\begin{verbatim}
Contract sample {
    Contract interf
    int x
    function m (Contract addr): int{
        x = addr.f(interf)
        x = interf.g(addr)
        return x
    }

}
\end{verbatim}

Nell'esempio di codice \texttt{scl} vede un campo di tipo contratto
(\texttt{interf}) e un parametro di tipo contratto (\texttt{addr}), la
compilazione verso Solidity è:

\begin{verbatim}
interface Interf0{
    function g(address) external returns (int);
}
interface Interf1{
    function f(address) external returns (int);
}
contract sample {
    Interf0 interf;
    int x;

    function m(address addr) public returns (int){
        x = Interf1(addr).f(address(interf));
        x = interf.g(addr);
        return x;
    }
}
\end{verbatim}

Notiamo quindi che \texttt{interf} è tradotto come un oggetto con la sua
interfaccia \texttt{Interf0}, mentre \texttt{addr} che nel codice
\texttt{scl} è sempre del tipo \texttt{Contract}, è un oggetto generico
di tipo \texttt{address}-- ma nonostante ciò ad \texttt{addr} viene
associata l'interfaccia \texttt{Interf1}. Quando viene chiamata una
funzione su \texttt{addr}, viene prima fatto il cast in
\texttt{Interf1}, mentre quando viene chiamata una funzione su
\texttt{interf} non viene fatto nessun cast. Invece, nel passaggio di
parametri, si ha il cast verso \texttt{address} quando viene passata
\texttt{interf}, mentre non si ha il cast di \texttt{addr} siccome è già
del tipo \texttt{address}. Notiamo che le due funzioni chiamate sono
aggiunte nelle relative interfacce: la funzione \texttt{g}, chiamata da
\texttt{interf} è aggiunta in \texttt{Interf0}, e la funzione \texttt{f}
chiamata da \texttt{addr} è aggiunta in \texttt{Interf1}.

Rimane da tradurre la situazione in cui si ha un assegnamento di
contratti con interfacce diverse. In pratica si ha che deve avvenire un
cast verso l'interfaccia del \emph{lhs}, però, dal momento che i tipi in
Solidity sono nominali, sarebbe necessario anche che i metodi
dell'interfaccia del \emph{rhs} vengano aggiunti nel \emph{lhs}. Si
potrebbe quindi aggiungere manualmente i metodi all'interfaccia del
\emph{lhs}, o comunque far ereditare il \emph{lhs} al \emph{rhs}.
Abbiamo però aggirato il problema in modo che Solidity se ne
preoccupasse a tempo di esecuzione, invece che durante la compilazione.
Infatti facciamo prima un cast dal \emph{rhs} al suo \texttt{address} e
poi dall'indirizzo all'interfaccia. In questo modo è possibile fare
qualsiasi cast tra due diversi oggetti senza che il compilatore Solidity
sollevi un'eccezione.

\begin{verbatim}
Contract p
Contract q
p = q
\end{verbatim}

L'assegnamento diventa:

\begin{verbatim}
Interf0 p;
Interf1 q;

p = Interf0(address(q));
\end{verbatim}

\hypertarget{inizializzazione-degli-indirizzi}{%
\section{Inizializzazione degli
indirizzi}\label{inizializzazione-degli-indirizzi}}

Definito quindi come avviene la traduzione per i tipi \texttt{Contract}
di \texttt{scl}, non è ancora chiaro però come la compilazione possa far
conoscere ad ogni contratto i riferimenti degli altri contratti della
configurazione. Ovviamente in Solidity sarebbe necessario che un
contratto debba avere gli indirizzi degli altri contratti. Questi
indirizzi non sono noti a tempo di compilazione poiché sono indirizzi
relativi al posizionamento del contratto nella blockchain e quindi sono
assegnati al momento del deploy. Per fare in modo che a tempo di deploy
si possano comunicare al contratto tutti gli indirizzi richiesti è
necessario che ogni contratto abbia un campo per ogni altro contratto
della configurazione. Viene poi creata una funzione \texttt{init} che
assegna gli indirizzi passati come parametro ai rispettivi campi. Questa
funzione verrà poi chiamata in fase di deploy quando saranno noti gli
indirizzi effettivi.

\begin{verbatim}
Contract a{}
Contract b{}
Contract c{}
\end{verbatim}

La configurazione base mostrata nell'esempio viene compilata in:

\begin{verbatim}
contract a {
    Interf1 c;
    Interf0 b;
    bool initialize = false;
    
    function init(address _b, address _c) public {
        if (!initialize){
            b = Interf0(_b);
            c = Interf1(_c);
            initialize = true;
        }
    }
}
contract b {
    Interf3 c;
    Interf2 a;
    bool initialize = false;
    
    function init(address _a, address _c) public {
        if (!initialize){
            a = Interf2(_a);
            c = Interf3(_c);
            initialize = true;
        }
    }
}
contract c {
    Interf5 b;
    Interf4 a;
    bool initialize = false;

    function init(address _a, address _b) public {
        if (!initialize){
            a = Interf4(_a);
            b = Interf5(_b);
            initialize = true;
        }
    }
}
\end{verbatim}

dove la variabile booleana \texttt{initialize} assicura che la funzione
\texttt{init} non venga chiamata più volte. In questo modo si evita che
un attaccante possa cambiare l'indirizzo di un contratto noto in un
indirizzo di un contratto terzo. Così ogni contratto si può riferire
agli altri contratti della configurazione.

\hypertarget{considerazioni-implementative}{%
\section{Considerazioni
implementative}\label{considerazioni-implementative}}

\hypertarget{associazione-tra-i-tipi-di-scl-e-solidity}{%
\subsection{\texorpdfstring{Associazione tra i tipi di \texttt{scl} e
Solidity}{Associazione tra i tipi di scl e Solidity}}\label{associazione-tra-i-tipi-di-scl-e-solidity}}

A livello implementativo, la traduzione da AST di \texttt{scl} a AST di
Solidity è abbastanza semplice. Si parte creando un'associazione tra i
tipi di dato in \texttt{scl} e tipi in Solidity. Si è infatti visto
essere gli stessi ad eccezione degli umani, che non sono presenti in
Solidity, e dei contratti di \texttt{scl} che vengono tradotti in
indirizzi o oggetti di tipo interfaccia. Si ha quindi un'associazione
abbastanza semplice:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let}\NormalTok{ get_typename  : }\KeywordTok{type}\NormalTok{ a b. a typename -> b tag -> any_typename =}
 \KeywordTok{fun}\NormalTok{ typ tag ->}
  \KeywordTok{match}\NormalTok{ tag }\KeywordTok{with}
\NormalTok{  | SmartCalculus.Int -> Typename Int}
\NormalTok{  | SmartCalculus.Bool -> Typename Bool}
\NormalTok{  | SmartCalculus.}\DataTypeTok{String}\NormalTok{ -> Typename }\DataTypeTok{String}
\NormalTok{  | SmartCalculus.ContractAddress -> Typename typ}
\NormalTok{  | SmartCalculus.HumanAddress -> }\DataTypeTok{raise}\NormalTok{ CompilationFail}
\end{Highlighting}
\end{Shaded}

Pertanto se si cerca di tradurre il tipo umano viene sollevata
un'eccezione, mentre per tradurre il contratto, a seconda del contesto,
deve essere specificato il relativo tipo di ritorno (o indirizzo o
interfaccia). In tutti gli altri casi il tipo rimane il medesimo.

Una volta creata questa associazione, la costruzione dell'albero è
banale in quanto quasi tutti i costrutti \texttt{scl} sono già presenti
in Solidity. In più grazie all'implementazione tramite GADT dei due
alberi non è necessario nessun vero \emph{type checking}: sappiamo che
l'albero \texttt{scl} è già ben tipato, allora se viene rispettata
l'associazione anche l'AST Solidity sarà ben tipato. Rimane solo da
implementare i costrutti di \texttt{scl} non presenti in Solidity, in
particolare \texttt{symbol}, e mettere in piedi il meccanismo per
associare ad ogni contratto la sua interfaccia.

\hypertarget{implementazione-del-costrutto-symbol}{%
\subsection{\texorpdfstring{Implementazione del costrutto
\texttt{symbol}}{Implementazione del costrutto symbol}}\label{implementazione-del-costrutto-symbol}}

Il costrutto \texttt{symbol} di \texttt{scl} permette di assegnare una
stringa a un intero. Il razionale è che, se ci si vuole riferire a una
costante senza interesse verso l'effettivo valore, è più comodo usare
una stringa piuttosto che un intero. Ovviamente Solidity non mette a
disposizione alcuna funzione che implementa symbol. Si può però usare il
tipo \texttt{mapping} di Solidity, che rende possibile definire delle
funzioni hash. In particolare si può creare una funzione hash
\texttt{symbol} che associ a una stringa il relativo intero. Per
implementare questa funzione, però, è necessario che a stringhe già
definite sia associato lo stesso valore -- altrimenti si perderebbe la
definizione di funzione hash. Il compilatore pertanto, durante la
costruzione dell'albero, deve conoscere quali stringhe di
\texttt{symbol} sono già state utilizzate. Similmente a quanto avvenuto
nell'implementazione del parser, anche per l'implementazione del
compilatore è necessaria una tabella che viene riempita a cui il
compilatore fa riferimento. In questa tabella devono essere contenuti
tutte le stringhe di \texttt{symbol} già conosciute, in modo che quando
si ha la traduzione di questo costrutto la relativa stringa viene
aggiunta alla tabella solo nel caso in cui non sia ancora presente.
Quando poi verrà tradotto l'AST In codice Solidity è necessario che nel
costruttore venga associato a ogni \texttt{symbol} un valore diverso.

\begin{verbatim}
Contract a{
    function foo() : int{
        x = symbol("something")
        x = symbol("else")
        x = symbol("something")
        return x
    }
}
\end{verbatim}

Il contratto \texttt{a} verrà quindi compilato in

\begin{verbatim}
contract a {
    mapping (string => int) symbol;
    int x = 0;
    constructor() payable public {
        symbol['else'] = 0;
        symbol['something'] = 1;

    }
    function foo() payable public returns (int ){
        x = symbol['something'];
        x = symbol['else'];
        x = symbol['something'];
        return x;
    }
}
\end{verbatim}

Si ha quindi che viene fatto il \texttt{symbol} di solo due stringhe
diverse \texttt{"something"} ed \texttt{"else"}, e a ognuna di queste
viene assegnato un valore diverso.

\hypertarget{implementazione-delle-interfacce}{%
\subsection{Implementazione delle
interfacce}\label{implementazione-delle-interfacce}}

In \texttt{scl} è possibile che si abbia un riferimento a una variabile
senza che questa sia dichiarata, ma questo non è possibile in Solidity.
Ancora una volta è necessaria una tabella nella quale all'occorrenza
vengano aggiunti i campi con il relativo tipo (esattamente come avveniva
in scl). In questo modo quando viene fatta la traduzione in codice
Solidity si aggiungono nelle dichiarazioni tutti i campi in precedenza
non dichiarati. Questa tabella è inoltre utile per implementare le
interfacce di cui precedentemente si è discusso.

Si è visto infatti che ogni contratto -- inteso come variabile oggetto
nella classe -- ha bisogno di essere associato a un'interfaccia. Anche
in questo caso è necessario che il compilatore conosca questa
associazione, in modo da poter modificare, aggiungendo metodi, le
interfacce già presenti. Questa associazione è mantenuta all'interno
della tabella delle variabili: ad ogni variabile di tipo contratto viene
aggiunto un valore con l'id (che sarebbe il nome) dell'interfaccia
relativa. Perciò è necessaria anche un'altra tabella in cui ad ogni
interfaccia è associata la lista dei suoi metodi. Per cui, quando si ha
una chiamata di funzione su un contratto (e quindi il compilatore deve
aggiungere la funzione all'interfaccia del contratto), viene prima
cercato l'id dell'interfaccia nella tabella delle variabile, poi dall'id
si trova la relativa interfaccia nella tabella che contiene tutte le
interfacce: non rimane che aggiungere a questa il metodo.

Si è visto che l'albero di sintassi astratta generato cerca di essere il
più fedele possibile ai costrutti del linguaggio Solidity, quindi la
traduzione dall'AST al codice consiste semplicemente nell'attribuire a
ogni costrutto il giusta stringa.

\hypertarget{problemi-con-il-sistema-di-tipi-in-solidity}{%
\section{Problemi con il sistema di tipi in
Solidity}\label{problemi-con-il-sistema-di-tipi-in-solidity}}

Solidity è un linguaggio tipato staticamente, e ciò che ci si aspetta
quindi è che il compilatore Solidity garantisca la condizione di
\emph{type-safety}, e nel caso non vengano rispettati dei vincoli di
tipo non generi il bytecode necessario per l'esecuzione. Durante
l'implementazione della compilazione, però, ci si è accorti come sia
semplice aggirare il controllo statico dei tipi del compilatore.
L'esempio seguente ne è la prova:

\begin{verbatim}
contract c1 {
    function foo() payable external returns (bool){
        return true;
    }
}

contract c2 {
    function fie(bool) payable external returns (int){
        return 42;
    }
}

contract sample{

    function test(int, bool) payable public{
        c2 b = new c2();
        b.foo();
    }
}
\end{verbatim}

In questo caso nella funzione \texttt{test} di \texttt{sample} il
contratto \texttt{b} sta facendo una chiamata a un metodo di una classe
che non è sua: il compilatore giustamente solleva un errore di tipo.
Basta però fare una semplice modifica solamente alla funzione
\texttt{test} e il compilatore non solleverà più l'eccezione.

\begin{verbatim}
contract sample{

    function test(int, bool) payable public{
        c2 b = new c2();
        c1(address(b)).foo();
    }
}
\end{verbatim}

Ci si chiede allora come viene fatto il cast da \texttt{c1} a
\texttt{c2} visto che sono due classi di contratti con metodi diversi.
Il cast di Solidity in realtà ha solo valenza sintattica: in realtà non
viene fatto nessun cast né a tempo di compilazione né durante la
compilazione. Quindi in questo caso non si riscontra nessun errore a
tempo di compilazione, ma verrà sollevato un errore a tempo di
esecuzione.

Questa mancanza di un controllo statico del cast, può risultare
particolarmente dannoso. Un pattern spesso usato nel linguaggio Solidity
è \texttt{msg.sender.transfer(n)} che consiste nel trasferire \texttt{n}
Ether all'indirizzo del chiamante, passando per la sua speciale funzione
\emph{fallback}. Se questa non dovesse essere definita si avrebbe un
errore a tempo di esecuzione, che comporterebbe un mancato trasferimento
di denaro -- come ulteriormente approfondito da .

\hypertarget{conclusione-3}{%
\section{Conclusione}\label{conclusione-3}}

In questo capitolo si è mostrato come avviene la compilazione verso
Solidity per un programma in \texttt{scl}. Viene quindi prima fatta la
traduzione da AST \texttt{scl} a AST Solidity, e da quest'ultimo viene
generato il codice. Questi due procedimenti sono abbastanza banali, se
non per il fatto che in Solidity vengono definiti le classi dei
contratti, diversamente a quanto avviene in \texttt{scl} dove vengono
definiti gli oggetti. È necessario inoltre poter fare le chiamate di
funzioni sugli oggetti di tipo contratto, e questo è stato reso
possibile assegnando ad ogni tipo una sua interfaccia. Durante la
compilazione si sono riscontrati dei limiti del sistema di tipi del
linguaggio Solidity, in particolare si ha che nel cast non avviene
nessun controllo sul tipo, ma si fa solo in modo che il compilatore non
sollevi un'eccezione -- con particolari problemi di sicurezza che questa
pratica solleva.

\hypertarget{deploy}{%
\chapter{Deploy}\label{deploy}}

\hypertarget{introduzione-5}{%
\section{Introduzione}\label{introduzione-5}}

Una volta che abbiamo il codice Solidity mancano solo gli effettivi
contratti sulla blockchain. Per fare deploy è necessario uno script che
si colleghi alla rete e che crei l'istanza dei contratti. Come
linguaggio di scripting è stato scelto Python perché dispone dei mezzi
necessari per interagire con Ethereum. Per la fase di testing, invece di
creare i contratti direttamente sulla rete di Ethereum, è stata creata
una rete locale.

\hypertarget{implementazione-script-python}{%
\section{Implementazione script
Python}\label{implementazione-script-python}}

Il compilatore oltre al codice Solidity deve generare il codice dello
script Python. Questo codice si deve preoccupare quindi di creare tutti
i contratti della configurazione, avendo così per ciascuno il proprio
ABI e il proprio indirizzo. Per ogni contratto sono necessarie 3 cose:
in primo luogo serve che gli venga assegnato il \texttt{balance}
iniziale (), poi che venga chiamata la funzione \texttt{init} (a cui
vengono passati come parametri gli indirizzi degli altri contratti), e
per ultimo che vengano salvati l'indirizzo e l'ABI, che costituiscono
gli elementi necessari per potersi riferire al contratto.

Per la creazione dei file, lo script deve compilare il codice Solidity
generato in precedenza, questo è reso possibile dalla funzione
\texttt{compile\_source} della libreria \texttt{solc} che compila il
file Solidity passato per parametro: in particolare crea una lista dove
all'interno di ogni elemento è presente l'id e l'interfaccia di ogni
contratto.

La libreria invece che permette di interagire con Ethereum invece è
\texttt{Web3.py}. Questa mette a disposizione metodi per collegarsi a un
nodo di Ethereum e permette di generare contratti nella blockchain coi
quali interagire. Dall'interfaccia del contratto generata dopo la
compilazione è possibile estrapolare l'ABI e il bytecode relativi ai
contratti, che sono gli elementi necessari per costruire il contratto.
Una volta che si ha l'oggetto contratto è possibile aggiungere il
\texttt{balance} iniziale relativo passandolo come \texttt{value} al
costruttore. Una volta chiamato il costruttore il contratto viene
aggiunto nella blockchain e gli viene assegnato un indirizzo:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ deploy_contract(w3, contract_interface, balance):}
\NormalTok{    contract }\OperatorTok{=}\NormalTok{ w3.eth.contract(}
\NormalTok{        abi}\OperatorTok{=}\NormalTok{contract_interface[}\StringTok{'abi'}\NormalTok{],}
\NormalTok{        bytecode}\OperatorTok{=}\NormalTok{contract_interface[}\StringTok{'bin'}\NormalTok{])}
\NormalTok{    tx_hash }\OperatorTok{=}\NormalTok{ contract.constructor().transact(\{}\StringTok{'value'}\NormalTok{: balance\})}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'waiting for address...'}\NormalTok{)}
\NormalTok{    address }\OperatorTok{=}\NormalTok{ w3.eth.waitForTransactionReceipt(tx_hash)}
    \ControlFlowTok{return}\NormalTok{ address}
\end{Highlighting}
\end{Shaded}

Dopo che un contratto è stato creato, è possibile chiamare qualsiasi
funzione del contratto con visibilità \texttt{external} o
\texttt{public}; quindi è possibile anche impostare gli indirizzi
chiamando la funzione \texttt{init} del contratto. Lo script deve
comunicare anche tutte le informazioni necessarie per rendere possibile
nuovamente il deploy della stessa configurazione in un secondo momento.
Sostanzialmente per ogni oggetto contratto deve essere comunicato
l'indirizzo e l'ABI, in modo da poter ricreare il medesimo contratto: il
primo consiste in una stringa che lo script stampa, mentre il secondo è
un dizionario in Python che viene salvato come file JSON -- e di detto
file viene stampato il percorso.

\hypertarget{conclusione-4}{%
\section{Conclusione}\label{conclusione-4}}

Si è visto che il compilatore oltre a generare il codice Solidity che
definisce i contratti in modo conforme alla struttura \texttt{scl},
genera un codice Python che, quando viene eseguito, fa l'effettivo
deploy dei contratti sulla blockchain Ethereum costruita in una rete
locale. Questo codice oltre a fare il deploy inizializza i contratti con
il relativo \texttt{balance} e, tramite la funzione \texttt{init},
permette che ogni contratto conosca effettivamente gli indirizzi sulla
blockchain di tutti gli altri contratti della configurazione. Una volta
eseguito questo codice si hanno tutti gli strumenti per fare il deploy
al fine di rendere effettivi i contratti creati in \texttt{scl} e poter
condurre analisi su questi.

\hypertarget{conclusione-5}{%
\chapter{Conclusione}\label{conclusione-5}}

In questo lavoro abbiamo visto il processo che ha portato alla
realizzazione di un'infrastruttura che permette di eseguire
completamente le istanze di \emph{smart contract} definite dal
linguaggio \texttt{scl} -- che in precedenza era solo un linguaggio
teorico su cui fare analisi.

Questo è stato reso possibile in un primo momento implementando un
parser, che assegna al linguaggio \texttt{scl} una sintassi in modo da
rendere più semplice la stesura del codice. Abbiamo visto che questo
parser è LL(1) quindi, operando in maniera ricorsiva, dalla radice
costruisce (da sinistra a destra) un albero di derivazione per il testo
in input nella grammatica definita. In aggiunta è stato implementato un
compilatore da \texttt{scl} a Solidity, che per ogni contratto
\texttt{scl} crea la relativa classe. Per riprodurre una configurazione
\texttt{scl} (caratterizzata dal fatto che tutti i contratti conoscono i
riferimenti agli altri contratti della configurazione), abbiamo fatto in
modo che in Solidity ogni classe relativa a un contratto contenga i
campi con i riferimenti necessari. Per creare le istanze relative alle
classi di Solidity abbiamo fatto generare al compilatore un codice
Python che -- su una rete di testing locale -- istanziasse i contratti
definiti in Solidity e comunicasse ad ogni contratto i riferimenti
necessari, rendendo possibile il deploy sulla blockchain.

La realizzazione di questa infrastruttura ha dato luogo a diversi
argomenti di interesse. Prima di tutto abbiamo visto come i GADT di
OCaml permettano di implementare una \emph{Intrinsically Typed Data
Structure} e, nel contesto del parser e del compilatore, abbiamo visto
come i GADT evitino di sottoporre gli AST a ridondanti controlli di
tipo. Abbiamo avuto modo di sperimentare anche la tecnica dei parser
combinator, vedendo come questa permetta di definire in modo modulare il
comportamento del parser nelle notazioni della grammatica. Inoltre,
durante la fase di implementazione abbiamo reso noti i problemi
riscontrati col sistema di tipi di Solidity: sebbene sia un linguaggio
con controllo statico dei vincoli di tipo, mi sono reso conto che è
facile scrivere del codice mal tipato in cui il compilatore non rilevi
errori di tipo.

In termini di tempo il mio lavoro ha richiesto circa 400 ore. Dal punto
di vista della quantità di codice l'implementazione del parser ha
richiesto circa 600 righe, buona parte necessarie per dover esprimere
ogni costrutto scl tramite il parsing e molte altre per che hanno a che
vedere con la gestione della tabella di parsing. Il compilatore invece
ha richiesto circa 800 righe di codice: una prima parte, costituita
all'incirca da un centinaio di righe, per la definizione dell'albero di
sintassi astratta; le restanti equamente divise tra il codice per la
generazione dell'AST per Solidity e il codice per permettere la
traduzione in linguaggio Solidity di ogni ramo dell'AST. A queste vanno
aggiunte un altro centinaio di righe di codice necessarie per la
generazione del codice Python per il deploy.

\hypertarget{approfondimenti-futuri}{%
\section{Approfondimenti futuri}\label{approfondimenti-futuri}}

Il lavoro svolto lascia spazio ad altri approfondimenti futuri. In primo
luogo, per avere una compilazione più completa per \texttt{scl}, oltre a
realizzare la compilazione per gli attori contratto sarebbe necessario
realizzare anche la compilazione relativa agli attori utente. Ovviamente
questa non può avvenire verso Solidity -- che non permette di definire
gli utenti -- ma dovrebbe essere verso un linguaggio che permetta di
interagire con i contratti sulla blockchain (un tale linguaggio, ad
esempio, potrebbe essere Python). È inoltre possibile che in futuro ci
saranno diverse analisi, sempre relative agli \emph{smart contract}, che
potrebbero partire da linguaggi diversi da \texttt{scl}, ma con simili
caratteristiche. Un altro sviluppo futuro del mio lavoro potrebbe essere
quello di usare i tool che ho implementato per \texttt{scl} e
riadattarli a nuovi linguaggi.

\hypertarget{bibliografia}{%
\chapter{Bibliografia}\label{bibliografia}}

\hypertarget{ringraziamenti}{%
\chapter{Ringraziamenti}\label{ringraziamenti}}
\end{document}
